{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Magic Commands\n",
      "\n",
      "## Sessions Magics\n",
      "%help | Return a list of descriptions and input types for all magic commands. \n",
      "%profile | String | Specify a profile in your aws configuration to use as the credentials provider.\n",
      "%region | String | Specify the AWS region in which to initialize a session | Default from ~/.aws/configure\n",
      "%idle_timeout | Int | The number of minutes of inactivity after which a session will timeout. The default idle timeout value is 2880 minutes (48 hours).\n",
      "%session_id | Returns the session ID for the running session. \n",
      "%session_id_prefix | String | Define a String that will precede all session IDs in the format [session_id_prefix]-[session_id]. If a session ID is not provided, a random UUID will be generated.\n",
      "%status | Returns the status of the current Glue session including its duration, configuration and executing user / role.\n",
      "%list_sessions | Lists all currently running sessions by name and ID.\n",
      "%stop_session | Stops the current session.\n",
      "%glue_version | String | The version of Glue to be used by this session. Currently, the only valid options are 2.0 and 3.0. The default value is 2.0.\n",
      "%streaming | String | Changes the session type to Glue Streaming. \n",
      "%etl | String | Changes the session type to Glue ETL. \n",
      "\n",
      "## Glue Config Magics\n",
      "%%configure | Dictionary | A json-formatted dictionary consisting of all configuration parameters for a session. Each parameter can be specified here or through individual magics.\n",
      "%iam_role | String | Specify an IAM role ARN to execute your session with. | Default from ~/.aws/configure\n",
      "%number_of_workers | int | The number of workers of a defined worker_type that are allocated when a job runs. worker_type must be set too. The default number_of_workers is 5.\n",
      "%worker_type | String | Standard, G.1X, or G.2X. number_of_workers must be set too. The default worker_type is G.1X.\n",
      "%security_config | String | Define a Security Configuration to be used with this session. \n",
      "%connections | List | Specify a comma separated list of connections to use in the session.\n",
      "%additional_python_modules | List | Comma separated list of additional Python modules to include in your cluster (can be from Pypi or S3).\n",
      "%extra_py_files | List | Comma separated list of additional Python files From S3.\n",
      "%extra_jars | List | Comma separated list of additional Jars to include in the cluster.\n",
      "%spark_conf | String | Specify custom spark configurations for your session. E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer\n",
      "\n",
      "## Action Magics\n",
      "%%sql | String | Run SQL code. All lines after the initial %%sql magic will be passed as part of the SQL code. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "It looks like there is a newer version of the kernel available. The latest version is 0.35 and you have 0.34 installed.\n",
      "Please run `pip install --upgrade aws-glue-sessions` to upgrade your kernel\n",
      "Setting session ID prefix to delta-analysis\n",
      "Setting Glue version to: 3.0\n",
      "Current idle_timeout is 2880 minutes.\n",
      "idle_timeout has been set to 60 minutes.\n",
      "The following configurations have been updated: {'--enable-spark-ui': 'true', '--spark-event-logs-path': 's3://gis-spark-logs/', '--spark.jars.packages': 'io.delta:delta-core_2.12:1.0.1', '--spark.sql.extensions': 'io.delta.sql.DeltaSparkSessionExtension', '--spark.sql.catalog.spark_catalog': 'org.apache.spark.sql.delta.catalog.DeltaCatalog'}\n"
     ]
    }
   ],
   "source": [
    "%session_id_prefix delta-analysis\n",
    "%glue_version 3.0\n",
    "%idle_timeout 60\n",
    "%%configure\n",
    "{\n",
    "\"--enable-spark-ui\": \"true\",\n",
    "\"--spark-event-logs-path\": \"s3://gis-spark-logs/\",\n",
    "\"--spark.jars.packages\": \"io.delta:delta-core_2.12:1.0.1\",\n",
    "\"--spark.sql.extensions\": \"io.delta.sql.DeltaSparkSessionExtension\",\n",
    "\"--spark.sql.catalog.spark_catalog\": \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create a Glue session for the kernel.\n",
      "Worker Type: G.1X\n",
      "Number of Workers: 5\n",
      "Session ID: air-analysis--76fdac11-3ae9-4fbc-ac5b-9cbcec73c7e8\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 0.34\n",
      "--enable-glue-datacatalog true\n",
      "--enable-spark-ui true\n",
      "--spark-event-logs-path s3://<BUCKET>/gis-spark-logs/\n",
      "--spark.jars.packages io.delta:delta-core_2.12:2.0.0\n",
      "--spark.sql.extensions io.delta.sql.DeltaSparkSessionExtension\n",
      "--spark.sql.catalog.spark_catalog org.apache.spark.sql.delta.catalog.DeltaCatalog\n",
      "Waiting for session air-analysis--76fdac11-3ae9-4fbc-ac5b-9cbcec73c7e8 to get into ready status...\n",
      "Session air-analysis--76fdac11-3ae9-4fbc-ac5b-9cbcec73c7e8 has been created\n",
      "\n",
      "3.1.1-amzn-0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, lower, hour\n",
    "print(spark.version)\n",
    "day_to_analyze = \"2022-01-05\"\n",
    "df = spark.read.json(f\"s3://openaq-fetches/realtime-gzipped/{day_to_analyze}/1641409725.ndjson.gz\")\n",
    "df_air = spark.read.schema(df.schema).json(f\"s3://openaq-fetches/realtime-gzipped/{day_to_analyze}/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Hour|           no2_avg|\n",
      "+----+------------------+\n",
      "|   0|         37.823125|\n",
      "|   1|40.444137931034476|\n",
      "|   2|            45.133|\n",
      "|   3|         37.654375|\n",
      "|   4|53.437500000000014|\n",
      "|   5|           58.0984|\n",
      "|   6|58.881666666666675|\n",
      "|   7| 78.51407407407407|\n",
      "|   8| 65.86359999999999|\n",
      "|   9| 43.94166666666667|\n",
      "|  10|47.756190476190476|\n",
      "|  11|38.246562499999996|\n",
      "|  12| 45.30607142857143|\n",
      "|  13|42.872413793103455|\n",
      "|  14| 45.60785714285715|\n",
      "|  15| 38.22392857142857|\n",
      "|  16|32.498888888888885|\n",
      "|  17| 31.73413793103448|\n",
      "|  18| 32.16227272727272|\n",
      "|  19|28.679062499999997|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_city = df_air.filter(lower((df_air.city)).contains('delhi')).filter(df_air.parameter == \"no2\").cache()\n",
    "df_avg = df_city.withColumn(\"Hour\", hour(df_city.date.utc)).groupBy(\"Hour\").avg(\"value\").withColumnRenamed(\"avg(value)\", \"no2_avg\")\n",
    "df_avg.sort(\"Hour\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1-amzn-0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, lower, hour\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark (SparkAnalytics 1.0)",
   "language": "python",
   "name": "conda-env-sm_glue_is-glue_pyspark__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-sparkanalytics-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
